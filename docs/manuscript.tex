%
% Annual Cognitive Science Conference
% Sample LaTeX Paper -- Proceedings Format
%

% Original : Ashwin Ram (ashwin@cc.gatech.edu)       04/01/1994
% Modified : Johanna Moore (jmoore@cs.pitt.edu)      03/17/1995
% Modified : David Noelle (noelle@ucsd.edu)          03/15/1996
% Modified : Pat Langley (langley@cs.stanford.edu)   01/26/1997
% Latex2e corrections by Ramin Charles Nakisa        01/28/1997 
% Modified : Tina Eliassi-Rad (eliassi@cs.wisc.edu)  01/31/1998
% Modified : Trisha Yannuzzi (trisha@ircs.upenn.edu) 12/28/1999 (in process)
% Modified : Mary Ellen Foster (M.E.Foster@ed.ac.uk) 12/11/2000
% Modified : Ken Forbus                              01/23/2004
% Modified : Eli M. Silk (esilk@pitt.edu)            05/24/2005
% Modified : Niels Taatgen (taatgen@cmu.edu)         10/24/2006
% Modified : David Noelle (dnoelle@ucmerced.edu)     11/19/2014
% Modified : Roger Levy (rplevy@mit.edu)     12/31/2018

%% Change "letterpaper" in the following line to "a4paper" if you must.

\documentclass[10pt,letterpaper]{article}

\usepackage{hyperref}

\usepackage{cogsci}

% \cogscifinalcopy % Uncomment this line for the final submission 


\usepackage{pslatex}
\usepackage{apacite}
\usepackage{tikz}
\usepackage{float} % Roger Levy added this and changed figure/table
                   % placement to [H] for conformity to Word template,
                   % though floating tables and figures to top is
                   % still generally recommended!

%\usepackage[none]{hyphenat} % Sometimes it can be useful to turn off
%hyphenation for purposes such as spell checking of the resulting
%PDF.  Uncomment this block to turn off hyphenation.


%\setlength\titlebox{4.5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 4.5cm (the original size).
%%If you do, we reserve the right to require you to change it back in
%%the camera-ready version, which could interfere with the timely
%%appearance of your paper in the Proceedings.
\def\arraystretch{1.15}%  1 is the default, change whatever you need


\title{Errorless irrationality: removing error-driven components from the inverse base-rate effect paradigm}
 
\author{{\large \bf Lenard Dome (lenarddome@gmail.com)} \\
  Brain Research and Imaging Centre \\
  University of Plymouth, Research Way, Plymouth, PL6 8BU
  \AND {\large \bf Andy J. Wills (andy.wills@plymouth.ac.uk)} \\
  Brain Research and Imaging Centre \\
  University of Plymouth, Research Way, Plymouth, PL6 8BU}


\begin{document}

\maketitle

\begin{abstract}

The inverse base-rate effect is a robust irrational bias that arises when people face ambiguity.
The most prominent theories of this irrational bias depend on prediction error.
In this study, we gradually removed elements of a predictive learning design to test the extent to which error-driven processes underly this bias.
In our first experiment, we removed explicit feedback by implementing the inverse base-rate effect in an observational learning procedure. 
In our second study, we further removed any causal relationship between stimulus features and category labels by moving towards an unsupervised learning procedure.
This removed any information participants could use to identify category labels.
In both experiments, the inverse base-rate effect persisted and remained robust.
This outcome suggests that this irrational bias is independent of supervised learning procedures.
We propose that any theories and models of the inverse base-rate effect must manage information encoding and connection updates without explicit prediction error.
We end by proposing two clear paths for future investigations.

\textbf{Keywords:} 
irrationality; prediction error; inverse base-rate effect; categorization; contingency learning
\end{abstract}


\section{Introduction}

The \textit{inverse base-rate effect} \cite<IBRE, >{medin1988problem} is an irrational tendency in humans to overweigh rare events when faced with ambiguity.
In a traditional design, people learn to categorise two overlapping sets of features under two distinct category labels.
These sets share a single feature, $A$, and possess a unique feature, $B$ and $C$, predictive of their respective category label.
The training thus can be summarised under two trial types, which we will express as $AB \to common$ and $AC \to rare$.
During learning, these sets of features occur at different frequencies.
The features under the common label usually occur three times as much as features under the rare label \cite{kruschke1996base}.
Following training, people categorise features presented by themselves and in novel combinations.
People tend to optimally label uniquely predictive features, $B$ and $C$, with their respective common and rare labels when presented by themselves.
Responses on the shared feature $A$ tend to show base-rate following.
But when uniquely predictive features are paired, $BC$, people tend to respond with the rare category label.
According to Classical Probability Theory, the rational response is to categorise this ambiguous combination under the common label, because it is the most frequently occurring label.
This rare bias on ambiguous combinations of BC has been observed across a different variety of experimental manipulations \cite{kalish2001inverse,don2017effects,don2021attention,inkster2022effect,wills2014attention}.
For a more thorough introduction to this irrational bias, see a review by \citeA{don2021hearing}.

\subsection{Assumptions of theories of the IBRE}

The most prominent theories of the inverse base-rate effect involve an attentional mechanism that drives not only learning but responding as well.
These theories are formal models.
They are: a neural network with an exemplar-mediated attention to distinctive input, EXIT \cite{kruschke2001toward}, a three-layer neural network with competitive attentional gating, and a four-layer neural network with an additional rapid attentional shift \cite{paskewitz2020dissecting}.
All these explanations rely on a process that relocates attention in response to prediction errors - they update attentional values according to gradient descent.
Their explanation is simple.
During learning, people learn to label the $AB$ compound first, but they are still learning to label the $AC$ compound.
The presence of $A$ tend to push participants to generalise what they learned about $AB$, so they label $AC$ as common, which results in an error.
After making this error, attention relocates towards the uniquely predictive feature $C$ to reduce future errors.
This results in $C$ acquiring higher attentional salience than $B$.
When the ambiguous $BC$ compound is presented, this attentional allocation presists and thus $C$ will dominate responding.
This results in an irrational tendency to respond with the rare label.
According to these models, this irrationality results from an optimisation process that tries to reduce the errors people make.
This process creates an asymmetric cognitive representation that can be summarised as $AB$ belongs to common, $AB \to common$, and C belongs to rare, $C \to rare$ \cite{kruschke2001inverse}.

\subsection{Current Study}

In this work, we intend to test this basic assumption of these theories.
In the following two experiments, we will gradually remove components from the design traditionally associated with prediction error.
Our overarching goal is to investigate whether we can still observe the IBRE, even if we experimentally remove a crucial assumption of already existing accounts.
In our first attempt, building on the observational learning condition of Experiment 2 in \citeA{johansen2007paradoxical}, we implement the canonical IBRE design with a caveat that category labels are presented in unison with features.

In our second attempt, we further remove the causal relationship between features and category labels.
The goal was to remove any design component that might affect attentional allocation or the development of asymmetric representation in response to errors.
Any presumption of a causal relationship might inadvertently relocate attention in line with the direction of causality between features and labels.

\subsection{Related Work}

To our knowledge, there is only one attempt to implement the IBRE procedure without explicit feedback.
In terms of a clear observational-learning version of the IBRE, \citeA{johansen2007paradoxical} included the result of a short pilot experiment in their Appendix.
Unfortunately, there is no statistical analysis confirming that $BC \to rare$ is reliably different than $BC \to common$.
Given that sample size they report ($n = 16$), there is a chance that the study is underpowered.
There are also no details about the procedure of this experiment.
Therefore, we cannot make direct comparisons.
Nonetheless, in their Experiment 2, \citeA{johansen2007paradoxical} tried to observe the inverse base-rate effect both in a predictive-learning condition and in an observational-learning condition.
In the observational learning condition, category labels and features appeared together at the same time on the computer screen.
Their design involved disjoint cues where categories shared no features in common.
The canonical IBRE design involves a shared feature during training \cite{kruschke2001inverse, wills2014attention}.
According to the theories of the IBRE, this shared feature facilitates attentional relocation.
This attentional tuning in turn pushes responding toward the rare label.
In contrast, \citeA{johansen2007paradoxical} trained participants on $AB \to common$ and $C \to rare$.
Similarly, the $common$ category occured three times as often as $rare$.
Their design was optimized to investigate the hypothesised asymmetric cognitive representation of the two categories.
As a result, the only instance when they observed a rare bias was when the common feature, $B$ ,presented in compound during training was paired with a rare, $C$, feature presented by itself during training.
This provided evidence for the asymmetric cognitive representation \cite{kruschke2001inverse} hypothesised to develop during training.

Nonetheless, \citeA{johansen2007paradoxical} demonstrated that the inverse base-rate effect can occur without the traditional predictive learning design.
In on of the conditions in their Experiment 3, the canonical inverse base-rate design (including the shared cue) was implemented in a list format.
In this format, the trial-by-trial presentation of training items was turned into a list of 12 items fitted on a single page.
In this condition, participants still exhibited the rare preference on $BC$ trials.
In another condition of Experiment 3, participants recieved the information about outcome frequencies as a summary before testing.
After learning about feature-label information in this manner, participants did not show the IBRE but was matching the base-rate.
These experiments gives us evidence about another boundary condition for the IBRE - sequential presentation of training items.
% Need to elaborate why this is relevant.

Additionally, there are at least three studies which look at error-driven processes in the IBRE.
\citeA{don2019learned} demonstrated that on $AC$ trials, people fixated on $C$ longer than on $A$ both pre-responding during stimulus presentation and post-responding during feedback.
This fixation bias increased with more training.
They also observe greater fixation on $C$ on $AC$ trials, relative to $B$ on $BC$ trials.
Interestingly, there was no difference between fixation time of $C$ and $B$ during $BC$ trials.
% still consistents with EXIT
\citeA{wills2014attention} observed posterior selection negativity and concurrent frontal positivity for C relative to B, which gave evidence for an error-driven selective attentional learning process.
These studies gave evidence that attentional reallocation occurs in line with the mechanisms of EXIT.
\citeA{inkster2022neural} carried out a direct investigation into brain regions underlying error-driven learning in the IBRE.
Their ROI analysis explicitly targeted areas that were hypothesised to be involved in the computation of prediction error.
They showed that these areas exhibited greater activation during the test phase for C relative to B with a presence of a shared cue during training.
It is reasonable to suggests that attentional occurs in a standard supervised learning paradigm and it is driven by prediction error.
These three studies, \citeA{kruschke2005eye}, \citeA{wills2014attention} and \citeA{inkster2022neural} gave strong evidence in support of error-driven attentional learning accounts of the IBRE.
In our study, we will look for the effect while trying reduce the chance that cognitive processes calculate prediction error through modifying the experimental design.
In contrast, they looked for the neural substrates of error-driven processes incoporated into explanations of the effect.
In sum, these studies provide support for an attentional reallocation mechanism that is mediated by prediction error.
% This presumes that prediction error is necessary for the inverse base-rate effect.
% Arguably, one can predict that if there is no clear explicit design component (feedback) promoting prediction error as conceptualised in the models, the IBRE will not occur.

\section{Experiment 1}

Below, we detail our first attempt to test whether we could observe the rare response bias without an explicit error-driven psychological mechanism.
The design component which is most likely to result in any error-driven tuning is feedback.
To remove feedback, Experiment 1 will present category labels simultaneously with their respective features.
We retain the sequential property of the experiment, which means that participants learn about feature and category relationships on a trial-by-trial basis.
% LD: work out how models might predict rational responding?

Experiment 1 is a conceptual replication of an experiment included in the Appendix of \citeA{johansen2007paradoxical}.
The only information available is the list of test items (23), the doubled-up design (2 sets of categories and features), and the sample size.
We substantially simplified our implementation by removing the doubled-up design and reducing the number of test items to 6.

\subsection{Method}

\subsubsection{Participants}

Participants were undergraduate students who received course credit for their participation.
We recruited 169 participants online through the SONA recruitment system.

\subsubsection{Apparatus}

The experiment was programmed in JsPsych \cite{deleeuw2015JsPsych} to be run in a web browser.
Participants completed the experiment on their personal computers.
The experiment did not allow the use of tablets and smartphones.

\subsubsection{Stimuli}

Category labels corresponded with response keys and were called Disease \textbf{Z} and Disease \textbf{L}.
Category features were symptoms: fever, headache, and rash.
These physical features were randomly allocated to abstract features, A, B, and C at the beginning of each session.
Features and labels appeared in full sentences, such as '\textit{John has fever and rash, which belongs to disease Z}'.
Names were randomly drawn from a pool of male and female first names.
The list was compiled from an online repository of popular baby names\footnote[1]{The list was taken and later curated from a GitHub repository: \href{https://github.com/aruljohn/popular-baby-names}{https://github.com/aruljohn/popular-baby-names}.}.
We selected the 50 most popular male and female names from 2021.
Disease names corresponded to response keys and were randomly allocated to either the common or rare category label at the beginning of each session.

\subsubsection{Procedure}

Table \ref{tab:abstract-exp1} summarises the abstract design of the experiment.
This design is the simplest implementation of the IBRE procedure to date.
Participants completed two phases: a training and a test phase.
In the training phase, they encountered descriptions of people, the symptoms they experienced, and their respective diseases.
These descriptions appeared in the format of '\textit{John has fever and rash, which belongs to disease Z}'.
Participants studied these examples and when they were ready to move on, they pressed the spacebar.
They needed to complete reading the description within 5 seconds.
If the 5 seconds threshold has passed, a screen appeared with the message '\textit{Please respond faster!}'.
In each training block, participants encountered 6 common diseases (common category exemplars) and 2 rare diseases (rare category exemplars).
After the second block of training, participants were given a choice.
They could either move straight to the test phase or complete another training block.
A prompt appeared saying that '\textit{Now you have the option to skip the rest of the training phase and move straight to the test phase. If you think you need some more time, you can continue training and study more patients.}'.
There were a maximum of 5 blocks they could complete.

In the test phase, participants judged individual symptoms and novel combinations of old symptoms, see Table \ref*{tab:abstract-exp1}.
Symptoms appeared in a sentence, such as '\textit{John has a fever.}', with a prompt asking participants to label what disease the person has, '\textit{Does the patient have disease Z or disease L?}'.
Participants had to respond by pressing either Z or L on the keyboard.
They had 10 seconds to do so, otherwise, a '\textit{Please respond faster!}' message appeared.
After the button press, there was no feedback,
Each unique test item and training item (occurring in the test phase) was repeated 20 times.
So, the test phase included 120 trials, which were broken down into 5 blocks of 24 trials.

\begin{table}[!ht]
  \begin{center}
    \caption{Abstract design of Experiment 1 including both test and training phases. \\}
    \label{tab:abstract-exp1}
    \begin{tabular}{llr} % text alignments
      \textbf{Training (Relative Frequencies)} & \textbf{Test}& \\
      \hline
      % & \\
      $AB \to common_{1}$ (x 3) &  A, B, C,         &  \\
      $AC \to rare_{1}$   (x 1) &  AB, AC, BC      & x 20 \\
      \hline
    \end{tabular}
  \end{center}
\end{table}

\subsubsection{Analysis}

In order to test the presence of the IBRE, we calculated a Bayes Factor for a one-sample design.
We calculate the probability of responding with the rare label on the critical BC test item, $P(rare|BC)$, for each participant.
Then we tested this distribution of probabilities against the null, $mu = 0.5$, which denoted random responding.
If the Bayes Factor fell below 1/3, we concluded that participants' responses are not different from random responding.
If the Bayes Factor fell above 3, we concluded that participants' responses reliably differ from null.
If the mean probability of $P(rare|BC)$ is higher than 0.5, we conclude that we observed the IBRE.
Values lower than 0.5 would indicate rational responding.
We used the method implemented in the BayesFactor R package \cite{morey2022bayes}.

\subsubsection{Exclusion}

To match performance with the predictive learning implementations of the IBRE, we decided to exclude participants whose test performance on the training items fell below 0.75 accuracy.
This level of accuracy was the lowest at which the evidence that the participant performed better than chance was above the Bayes Factor of 3.
We calculated the Bayes Factor for binomial proportions via the method implemented in BayesFactor R package \cite{morey2022bayes}.

\subsection{Results and Discussion}

After exclusion, 125 participants made it into our main analysis.
In summary, the qualitative pattern in our results corresponds to the base result of the IBRE.
Table \ref*{tab:results-exp1} shows the group-level probabilities for each item.
Predictive features and training items are classified into their respective category.
Participants exhibited a reliable common preference for $A$, $M_{A} = 0.68$, 95\% HDI $[0.63, 0.73]$, $\mathrm{BF}_{10} = 2.45 \times 10^{7}$.
For this cue, people explicitly followed the base rate - responded rationally according to Probability Theory.
In contrast, participants showed a reliable rare preference for $BC$, $M_{BC} = 0.67$, 95\% HDI $[0.62, 0.72]$, $\mathrm{BF}_{10} = 1.11 \times 10^{7}$.
This gives us a sufficient amount of evidence to conclude that we have observed the IBRE.

\begin{table}[ht]
  \begin{center}
    \caption{Group-level mean probabilities for each stimulus presented during the test phase in Experiment 1 after exclusion. \\}
    \label{tab:results-exp1}
    \vskip 0.12in
    \begin{tabular}{rcc}
      \hline
      & $P(common)$ & $P(rare)$ \\
      \hline
      A & 0.69 & 0.31 \\
      AB & 0.94 & 0.06 \\
      AC & 0.08 & 0.92 \\
      B & 0.94 & 0.06 \\
      \textbf{BC} & \textbf{0.33} & \textbf{0.67} \\
      C & 0.04 & 0.96 \\
    \end{tabular}
  \end{center}
\end{table}

Thus the current study strongly confirms that the IBRE can be observed in an observational procedure.
In the current experimental design, the IBRE emerged in the absence of an explicit prediction error that drives the development of attentional allocation.
% This prediction error also drives the development of an asymmetric cognitive representation.
All EXIT-like theories of the IBRE rely on the assumption that this irrational rare preference arises as a result of optimising accuracy during the training phase.
In the absence of this explicit prediction error, EXIT-like theories cannot predict the presence of the IBRE.

One aspect of the current design is that participants can still experience internally-generated prediction errors from feature to categories on a trial-by-trial basis.
Given that the general assumption is that diseases cause symptoms, participants could likely assume a causal link between symptoms and diseases.
This assumed causal relationship can encourage participants to make not an explicit (responding with the category label via the keyboard) but an implicit prediction.
Informally, participants might think of a certain feature--label causal relationship while reading the sentences.
People then resolve errors between the expected and the observed feature--label causality by allocating attention to rare features to distinguish diseases.

In Experiment 2, we adress this by removing any design component that makes it clear to participants what the category label is.
And we also use stimuli that reduces the chance of people assuming any causal relationship between its features.

\section{Experiment 2}

In this experiment, we implemented the IBRE in a way most similar to cued-recall tasks.
Previous category labels were treated as features.
And features were selected to be solid black geometric shapes.
The task asked participants to memorise the arrangement of these shapes.
On each trial, we randomised the position of the geometric shapes in the arrangement.
This further minimised the chances of having any design component suggestive of which feature is the category label.

\subsection{Method}

\subsubsection{Participants}

We recruited 65 undergraduate students who completed the experiment for partial course credit.
Recruitment was done via the SONA recruitment system. \\

\subsubsection{Stimuli}

\begin{figure}
  \begin{center}
    \caption{Simple geometric shapes used as stimuli in Experiment 2.}
    \label{figure:exp2-stimuli}
    \includegraphics[scale=0.15]{figures/experiment_2_stimuli.pdf}
  \end{center}
\end{figure}

Stimuli were common solid geometric shapes, shown in Figure \ref*{figure:exp2-stimuli}.
Common and rare category labels were turned into features X and Y respectively.
Each shape was randomly allocated to one of the abstract features shown in Table \ref*{tab:abstract-exp2}.

\subsubsection{Procedure}

\begin{table}[!ht]
  \begin{center}
    \caption{Abstract design of Experiment 2 including both test and training phases. X and Y are in place of the category labels. During the test phase, participants needed to select either X or Y to complete the features shown below.\\}
    \label{tab:abstract-exp2}
    \begin{tabular}{llr} % text alignments
      \textbf{Training (Relative Frequencies)} & \textbf{Test}& \\
      \hline
      % & \\
      ABX x 3 &  A, B, C,        & \\
      ACY x 1 &  AB, AC, BC      & x 20 \\
      \hline
    \end{tabular}
  \end{center}
\end{table}

Table \ref*{tab:abstract-exp2} depicts the abstract experiment design.
Similar to the previous experiment, participants completed two phases: an encoding/training and a test phase.
In the training/encoding phase, participants were repeatedly exposed to the exemplars and were asked to memorise the arrangement of geometric shapes.
Compared to Experiment 1, exemplars were composed of three geometric shapes.
On each trial, geometric shapes appeared in random order so the position of features on the screen was completely counterbalanced.
This resulted in 24 trials within each block, which contained 18 common trials and 6 rare trials.
Similar to Experiment 1, participants could complete a maximum of 5 blocks.
After the first block, they were given a chance after completing each block to move straight to the test phase.
The trial structure and response deadlines corresponded to Experiment 1.

In the test phase, participants were shown \textit{incomplete} arrangement of geometric shapes and were asked to complete them.
On each test trial, they were asked to select either \textbf{X} or \textbf{Y} to complete the arrangement.
Similar to Experiment 1, each test item (incomplete arrangement of shapes) appeared 20 times.
Various arrangement of shapes appeared in the middle of the screen.
The response options X and Y with the corresponding shapes were shown below.
The prompt asked participants to pick one of the shapes to complete the arrangement.
Participants could respond by pressing either X or Y on the keyboard.
Similarly, the test phase was composed of 120 trials presented across 5 blocks of 24 trials.
\\

\subsubsection{Analysis and Exclusion}

We applied the same analysis and exclusion methods as in Experiment 1.

\subsection{Results and Discussion}

After exclusion, 30 participants made it into our analysis.
The group-level mean probabilities are shown in Table \ref{tab:results-exp2}.
The results are a qualitative and ordinal match to Experiment 1.
Participants showed a clear common preference for stimuli A, $M_{A} = 0.77$, 95\% HDI $[0.68, 0.87]$, $\mathrm{BF}_{10} = 10,316.41$.

\begin{table}[H]
  \begin{center}
    \caption{Group-level mean probabilities for each stimulus presented during the test phase in Experiment 2 after exclusion.\\}
    \label{tab:results-exp2}
    \vskip 0.12in
    \begin{tabular}{rcc}
      \hline
       & $P(common)$ & $P(rare)$ \\
      \hline
      A & 0.78 & 0.22  \\
      AB & 0.95 & 0.05 \\
      AC & 0.09 & 0.91 \\
      B & 0.92 & 0.07  \\
      \textbf{BC} & \textbf{0.35} & \textbf{0.65} \\
      C & 0.08 & 0.92 \\
    \end{tabular}
  \end{center}
\end{table}

Participants also showed a reliable rare preference on ambiguous BC trials, $M_{BC} = 0.64$, 95\% HDI $[0.53, 0.75]$, $\mathrm{BF}_{10} = 4.09$
This gives us a sufficient amount of evidence to conclude that we have observed the IBRE.

Here, we further demonstrated that the IBRE can arise without experimental-design components that explicitly promote an error-driven process.

\section{Discussion}

In this study, we tested a central assumption of the most prominent theories of the IBRE.
This central assumption was that the IBRE is caused by the presence of prediction error.

In our first experiment, we implemented an observational learning version of the canonical IBRE procedure.
This meant that features and category labels appeared on the screen at the same time.
Participants learned about categories by reading complete sentences that describe what symptoms people exhibit and what diseases they have.
The experiment included no feedback and required no responses from participants during training.
From a theoretical perspective, there was no opportunity for making an explicit error..
Nevertheless, we observed the inverse base-rate effect.
One limitation of this approach was that there are assumed causal relationships between features (symptoms) and labels (diseases).
These relationships might predispose participants to make feature-to-label predictions, which will result in prediction error and attentional relocation.

In our second experiment, we further removed the causal relationship between features and labels by changing the stimuli and their presentation.
Here, participants saw nothing but an arrangement of geometric shapes, where previous category labels were treated as features.
There were no causal links between features and labels.
When participants were asked to complete incomplete arrangements of these shapes, they still exhibited a rare bias on $BC$ trials.
We still observed the IBRE.

In both experiments, the IBRE occurred without any explicit detail in the experimental procedure that would result in prediction error.
Therefore, any theorised error-driven process must be able to operate without explicit feedback.
Most prominent theories and their corresponding formal specification rely on relocating attention in response to prediction error.
They are unable to accommodate the current experiments because they are not designed to encode information presented without feedback.

% LD: so it seems that Johansen et al treated asymmetric representation as an experimental condition and not as a theoretical construct
% LD: I think this is a problem because asymmetric representation is hypothesized to be an asymmetry in the way the two categories represented

The two experiments suggest that the necessary conditions to observe the IBRE are fewer than previously established.
In Experiment 2, the only remaining conditions are the two uniquely predictive features, an overlapping feature, sequential presentation and the base rate.
One hypothesised way asymmetric representation is manifested is the attentional tuning of cognitive representation of category exemplars.
This is not necessarily absent in our experiments but is not directly tested.
Our experiments do not give direct evidence against the role of attention in developing asymmetric representation or in its contributions to the emergence of the IBRE.
Nonetheless, it must not happen through an error-driven process as conceptualised in most prominent theories of the IBRE.
To further investigate this, the cued-recall procedure could incorporate eye-tracking to measure dwell time and order of information encoding.
If we observe more and longer fixations on $C$ relative to $B$ on BC trials, it can mean that attention might be allocated asymmetrically to drive the distinguishability of categories.
In that case, explanations do not need to invoke an explicit error-driven process.

maybe a secondary cause of why ibre occurs?

\section{Conclusion}

Across two experiments, we investigated whether the IBRE requires error-driven components of the experimental procedure.
In Experiment 1, we conducted a successful conceputal replication of \citeA{johansen2007paradoxical}, which gave evidence for the IBRE being independent of supervised learning procedures.
In addition, Experiment 2 further suggests that the IBRE generalises beyond simple predictive-learning \cite<e.g. >{medin1988problem,kruschke1996base,wills2014attention} and decision-making \cite{johansen2007paradoxical} paradigms.
This further suggest prediction error in terms of explicit feedback is not a necessary condition.
Theories of IBRE are inadequate to account for these findings, because of their inability to extend beyond supervised learning.

\section{Open Science}

We made available the two experiments written in javascript, the analysis code, the raw data, and all other supplementary materials.
Experiment 1 is shared via \href{https://osf.io/auwvt/?view_only=2dc8384074fa4bcf9f2e3937fdaee2b4}{OSF}, and \href{TBA}{GitHub}.
Experiment 2 is shared via \href{https://osf.io/2tmc4/?view_only=489ebc888ef84a6b9b904072cfbe74df}{OSF} and \href{TBA}{Github}.
The main repository that includes this manuscript and links to the materials for the two experiments can be found on \href{TBA}{GitHub}.

\section{Acknowledgement}

The data for Experiment 1 was collected as part of a final-year undergraduate project. We thank for the help and contributions of To Be Added.

\bibliographystyle{apacite}

\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}

\bibliography{library}

\end{document}
